{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "test = pd.read_csv('./data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea',\n",
    "          'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']]\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결측치 하나 최빈값으로 채움\n",
    "X['BsmtFinSF1'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 평균값으로 채움\n",
    "X['TotalBsmtSF'].fillna(1045.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 최빈값으로 채움\n",
    "X['GarageCars'].fillna(2.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 평균값으로 채움\n",
    "X['GarageArea'].fillna(473.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bigBro\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# 결측치가 존재하는 MasVnrArea, GarageYrBlt 제거\n",
    "X.drop(['MasVnrArea', 'GarageYrBlt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bigBro\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=14, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bigBro\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "1400/1400 [==============================] - 3s 2ms/step - loss: 37819172849.3714\n",
      "Epoch 2/200\n",
      "1400/1400 [==============================] - 0s 217us/step - loss: 26481868518.4000\n",
      "Epoch 3/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 7994952371.2000\n",
      "Epoch 4/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 3112811274.5143\n",
      "Epoch 5/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 2943639498.9714\n",
      "Epoch 6/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 2838229875.2000\n",
      "Epoch 7/200\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 2714846822.4000\n",
      "Epoch 8/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 2593537940.8000\n",
      "Epoch 9/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 2479838573.0286\n",
      "Epoch 10/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 2373271477.4857\n",
      "Epoch 11/200\n",
      "1400/1400 [==============================] - 0s 200us/step - loss: 2283394004.0000\n",
      "Epoch 12/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 2196715070.4000\n",
      "Epoch 13/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 2138205738.5143\n",
      "Epoch 14/200\n",
      "1400/1400 [==============================] - 0s 205us/step - loss: 2081167069.7143\n",
      "Epoch 15/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 2031004679.7714\n",
      "Epoch 16/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1987422284.57140s - loss: 15530\n",
      "Epoch 17/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1953091063.8857\n",
      "Epoch 18/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1928418915.5429\n",
      "Epoch 19/200\n",
      "1400/1400 [==============================] - 0s 215us/step - loss: 1904429864.6857\n",
      "Epoch 20/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1896328558.4000\n",
      "Epoch 21/200\n",
      "1400/1400 [==============================] - 0s 216us/step - loss: 1866637650.7429\n",
      "Epoch 22/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1859577617.7143\n",
      "Epoch 23/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1850317818.2857\n",
      "Epoch 24/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1831554997.2571\n",
      "Epoch 25/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1825788589.6000\n",
      "Epoch 26/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1818552055.7714\n",
      "Epoch 27/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1815035493.6000\n",
      "Epoch 28/200\n",
      "1400/1400 [==============================] - 0s 217us/step - loss: 1800522033.3714\n",
      "Epoch 29/200\n",
      "1400/1400 [==============================] - 0s 221us/step - loss: 1799376760.3429\n",
      "Epoch 30/200\n",
      "1400/1400 [==============================] - 0s 199us/step - loss: 1789580353.0286\n",
      "Epoch 31/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1788987020.1143\n",
      "Epoch 32/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1780142338.5143\n",
      "Epoch 33/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1785205173.6571\n",
      "Epoch 34/200\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 1767839843.0857\n",
      "Epoch 35/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1762564809.0286\n",
      "Epoch 36/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1765803366.6286\n",
      "Epoch 37/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1759908415.7714\n",
      "Epoch 38/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1758936136.9143\n",
      "Epoch 39/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1747823593.1429\n",
      "Epoch 40/200\n",
      "1400/1400 [==============================] - 0s 231us/step - loss: 1757545603.7714\n",
      "Epoch 41/200\n",
      "1400/1400 [==============================] - 0s 219us/step - loss: 1747267781.7143\n",
      "Epoch 42/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1743000288.2286\n",
      "Epoch 43/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1740632360.1143\n",
      "Epoch 44/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1732412004.9143\n",
      "Epoch 45/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1733000615.0857\n",
      "Epoch 46/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1732959137.1429\n",
      "Epoch 47/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1742822906.2857\n",
      "Epoch 48/200\n",
      "1400/1400 [==============================] - 0s 205us/step - loss: 1720183484.5714\n",
      "Epoch 49/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1722106329.3714\n",
      "Epoch 50/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1719535708.5714\n",
      "Epoch 51/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1728377189.3714\n",
      "Epoch 52/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1721304239.3143\n",
      "Epoch 53/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1716249633.4857\n",
      "Epoch 54/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1716770893.2571\n",
      "Epoch 55/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1714791191.7714\n",
      "Epoch 56/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1710447260.0000\n",
      "Epoch 57/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1708078951.7714\n",
      "Epoch 58/200\n",
      "1400/1400 [==============================] - 0s 205us/step - loss: 1711604367.2571\n",
      "Epoch 59/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1703222461.60000s - loss: 17488\n",
      "Epoch 60/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1704179984.5714\n",
      "Epoch 61/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1698613162.8571\n",
      "Epoch 62/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1694335023.0857\n",
      "Epoch 63/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1692444967.0857\n",
      "Epoch 64/200\n",
      "1400/1400 [==============================] - 0s 199us/step - loss: 1692650850.1714\n",
      "Epoch 65/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1694412585.2571\n",
      "Epoch 66/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1685911697.9429\n",
      "Epoch 67/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1683423586.5143\n",
      "Epoch 68/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1681033965.9429\n",
      "Epoch 69/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1682620948.4571\n",
      "Epoch 70/200\n",
      "1400/1400 [==============================] - 0s 219us/step - loss: 1680933410.5143\n",
      "Epoch 71/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1678650581.7143\n",
      "Epoch 72/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1683616625.3714\n",
      "Epoch 73/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1679254604.5714\n",
      "Epoch 74/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1674091486.6857\n",
      "Epoch 75/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1670878727.3143\n",
      "Epoch 76/200\n",
      "1400/1400 [==============================] - 0s 217us/step - loss: 1670635694.0571\n",
      "Epoch 77/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1667421968.1143\n",
      "Epoch 78/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1682969186.2857\n",
      "Epoch 79/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1668651309.2000\n",
      "Epoch 80/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1668494936.0000\n",
      "Epoch 81/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1661715975.8857\n",
      "Epoch 82/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1656197655.5429\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 209us/step - loss: 1668884838.5143\n",
      "Epoch 84/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1659894834.5714\n",
      "Epoch 85/200\n",
      "1400/1400 [==============================] - 0s 216us/step - loss: 1650038637.8286\n",
      "Epoch 86/200\n",
      "1400/1400 [==============================] - 0s 199us/step - loss: 1642929571.4286\n",
      "Epoch 87/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1650028221.2000\n",
      "Epoch 88/200\n",
      "1400/1400 [==============================] - 0s 199us/step - loss: 1651121524.8000\n",
      "Epoch 89/200\n",
      "1400/1400 [==============================] - 0s 219us/step - loss: 1640192646.0571\n",
      "Epoch 90/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1642928224.2286\n",
      "Epoch 91/200\n",
      "1400/1400 [==============================] - 0s 199us/step - loss: 1655291820.6857\n",
      "Epoch 92/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1634422771.4286\n",
      "Epoch 93/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1642849055.5429\n",
      "Epoch 94/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1632468367.6571\n",
      "Epoch 95/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1635981745.3714\n",
      "Epoch 96/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1633938815.7714\n",
      "Epoch 97/200\n",
      "1400/1400 [==============================] - 0s 200us/step - loss: 1630186824.3429\n",
      "Epoch 98/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1632117784.2286\n",
      "Epoch 99/200\n",
      "1400/1400 [==============================] - 0s 199us/step - loss: 1627869301.4857\n",
      "Epoch 100/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1631011617.6000\n",
      "Epoch 101/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1632238566.4000\n",
      "Epoch 102/200\n",
      "1400/1400 [==============================] - 0s 205us/step - loss: 1630738673.2571\n",
      "Epoch 103/200\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 1621750744.2286\n",
      "Epoch 104/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1616173443.6571\n",
      "Epoch 105/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1619425183.2571\n",
      "Epoch 106/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1624099005.6000\n",
      "Epoch 107/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1621170910.0571\n",
      "Epoch 108/200\n",
      "1400/1400 [==============================] - 0s 220us/step - loss: 1613616858.8571\n",
      "Epoch 109/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1618261108.1143\n",
      "Epoch 110/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1608353892.5714\n",
      "Epoch 111/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1627712110.1714\n",
      "Epoch 112/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1604795088.3429\n",
      "Epoch 113/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1613754406.5143\n",
      "Epoch 114/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1610537657.7143\n",
      "Epoch 115/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1599976464.3429\n",
      "Epoch 116/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1597581426.9714\n",
      "Epoch 117/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1589650345.1429\n",
      "Epoch 118/200\n",
      "1400/1400 [==============================] - 0s 219us/step - loss: 1598612180.0000\n",
      "Epoch 119/200\n",
      "1400/1400 [==============================] - 0s 215us/step - loss: 1589758096.0000\n",
      "Epoch 120/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1591370280.3429\n",
      "Epoch 121/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1587913527.9429\n",
      "Epoch 122/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1595943301.7143\n",
      "Epoch 123/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1587107125.8286\n",
      "Epoch 124/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1583518512.6857\n",
      "Epoch 125/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1584630013.3714\n",
      "Epoch 126/200\n",
      "1400/1400 [==============================] - 0s 213us/step - loss: 1583450934.7429\n",
      "Epoch 127/200\n",
      "1400/1400 [==============================] - 0s 205us/step - loss: 1586787950.4000\n",
      "Epoch 128/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1582678312.1714\n",
      "Epoch 129/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1581121321.7143\n",
      "Epoch 130/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1576653976.5714\n",
      "Epoch 131/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1574571549.9429\n",
      "Epoch 132/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1575824107.5429\n",
      "Epoch 133/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1566605666.8571\n",
      "Epoch 134/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1579658294.7429\n",
      "Epoch 135/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1573277046.2857\n",
      "Epoch 136/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1570543978.6857\n",
      "Epoch 137/200\n",
      "1400/1400 [==============================] - 0s 218us/step - loss: 1561653654.9714\n",
      "Epoch 138/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1573108590.2857\n",
      "Epoch 139/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1561486691.2000\n",
      "Epoch 140/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1548522249.1429\n",
      "Epoch 141/200\n",
      "1400/1400 [==============================] - 0s 216us/step - loss: 1555584998.1714\n",
      "Epoch 142/200\n",
      "1400/1400 [==============================] - 0s 212us/step - loss: 1547976343.6571\n",
      "Epoch 143/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1552123427.4286\n",
      "Epoch 144/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1548049770.6286\n",
      "Epoch 145/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1548254786.7429\n",
      "Epoch 146/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1542868702.8571\n",
      "Epoch 147/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1550371117.0286\n",
      "Epoch 148/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1544631604.2286\n",
      "Epoch 149/200\n",
      "1400/1400 [==============================] - 0s 219us/step - loss: 1539876411.4286\n",
      "Epoch 150/200\n",
      "1400/1400 [==============================] - 0s 221us/step - loss: 1538882551.6571\n",
      "Epoch 151/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1550274405.9429\n",
      "Epoch 152/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1534350972.9143\n",
      "Epoch 153/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1530195469.3714\n",
      "Epoch 154/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1538779956.0571\n",
      "Epoch 155/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1542503264.4571\n",
      "Epoch 156/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1529987645.71430s - loss: 137103267\n",
      "Epoch 157/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1526205299.4857\n",
      "Epoch 158/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1536412662.7429\n",
      "Epoch 159/200\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 1532502885.3714\n",
      "Epoch 160/200\n",
      "1400/1400 [==============================] - 0s 218us/step - loss: 1526669054.0571\n",
      "Epoch 161/200\n",
      "1400/1400 [==============================] - 0s 216us/step - loss: 1523316807.9429\n",
      "Epoch 162/200\n",
      "1400/1400 [==============================] - 0s 208us/step - loss: 1516685995.4286\n",
      "Epoch 163/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1516569454.5714\n",
      "Epoch 164/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1515952297.0857\n",
      "Epoch 165/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1515592880.5714\n",
      "Epoch 166/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1512883405.7714\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 0s 202us/step - loss: 1511696584.3429\n",
      "Epoch 168/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1510995246.2857\n",
      "Epoch 169/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1496282548.8000\n",
      "Epoch 170/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1504341844.1714\n",
      "Epoch 171/200\n",
      "1400/1400 [==============================] - 0s 213us/step - loss: 1507931749.6000\n",
      "Epoch 172/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1499174796.4571\n",
      "Epoch 173/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1487711686.6286\n",
      "Epoch 174/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1493712007.2000\n",
      "Epoch 175/200\n",
      "1400/1400 [==============================] - 0s 213us/step - loss: 1498746004.6857\n",
      "Epoch 176/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1491783079.7714\n",
      "Epoch 177/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1487275965.8286\n",
      "Epoch 178/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1478956407.4286\n",
      "Epoch 179/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1495035995.7714\n",
      "Epoch 180/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1483428175.3143\n",
      "Epoch 181/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1479937132.8000\n",
      "Epoch 182/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1477782388.6286\n",
      "Epoch 183/200\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 1476901967.3143\n",
      "Epoch 184/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1472615739.7714\n",
      "Epoch 185/200\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 1472740675.0857\n",
      "Epoch 186/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1473123917.6000\n",
      "Epoch 187/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1471390369.8286\n",
      "Epoch 188/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1466739073.8286\n",
      "Epoch 189/200\n",
      "1400/1400 [==============================] - 0s 214us/step - loss: 1462048078.7429\n",
      "Epoch 190/200\n",
      "1400/1400 [==============================] - 0s 209us/step - loss: 1459515151.4286\n",
      "Epoch 191/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1460208905.2571\n",
      "Epoch 192/200\n",
      "1400/1400 [==============================] - 0s 205us/step - loss: 1452581874.7429\n",
      "Epoch 193/200\n",
      "1400/1400 [==============================] - 0s 204us/step - loss: 1466597670.9714\n",
      "Epoch 194/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1454636213.9429\n",
      "Epoch 195/200\n",
      "1400/1400 [==============================] - 0s 201us/step - loss: 1455998328.0000\n",
      "Epoch 196/200\n",
      "1400/1400 [==============================] - 0s 211us/step - loss: 1449927944.9143\n",
      "Epoch 197/200\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 1454604304.9143\n",
      "Epoch 198/200\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 1453536253.6571\n",
      "Epoch 199/200\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 1454714199.8857\n",
      "Epoch 200/200\n",
      "1400/1400 [==============================] - 0s 206us/step - loss: 1439707812.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1885c7ed1d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([166244.12 , 254475.61 , 126208.28 , 138166.12 , 164093.61 ,\n",
       "        35787.637, 214539.72 , 201139.12 , 140028.45 , 190258.48 ,\n",
       "       164370.81 , 192878.8  , 155212.19 , 220152.3  , 122010.08 ,\n",
       "       274558.22 , 135782.81 , 242494.78 , 143866.7  , 383982.28 ,\n",
       "       109073.3  , 125858.39 , 151192.69 , 253317.81 , 144849.94 ,\n",
       "       211727.28 , 176509.19 , 116779.02 , 125691.57 , 153896.56 ,\n",
       "       146811.17 , 155051.7  ,  85535.266, 120754.86 , 366067.78 ,\n",
       "       155109.12 , 230991.1  , 135595.5  , 211228.3  , 149979.38 ,\n",
       "       175280.27 , 195956.84 , 219773.53 , 302742.8  , 102686.305,\n",
       "       228776.1  ,  72216.94 , 236253.5  , 109782.03 ,  70032.97 ,\n",
       "       228568.06 , 132890.02 , 160264.31 , 129241.58 , 159575.75 ,\n",
       "       147811.38 ,  88738.84 , 151128.67 , 282769.8  , 300316.4  ,\n",
       "       222232.33 , 228713.62 , 126245.75 , 235367.03 , 176491.77 ,\n",
       "       138468.64 , 179051.64 , 152704.23 , 202136.12 , 205498.28 ,\n",
       "        86589.18 , 146928.75 , 188205.53 , 130443.25 , 181194.39 ,\n",
       "       190728.19 ,  42733.83 ,  52811.348, 210084.5  , 115881.68 ,\n",
       "       143021.4  , 169664.1  , 264968.53 , 128116.34 ,  79971.73 ,\n",
       "       241640.56 , 203641.88 ,  83529.55 , 222784.95 , 188414.42 ,\n",
       "       129056.44 , 158670.44 , 233927.19 , 241084.03 , 244779.44 ,\n",
       "       214163.53 , 204720.94 , 138292.48 , 238257.77 , 296985.22 ,\n",
       "       242008.44 , 240234.84 , 189735.53 , 138166.84 ,  96635.15 ,\n",
       "        83845.086, 111091.73 , 225517.66 ,  91730.22 , 163544.94 ,\n",
       "       241294.1  , 108434.836, 111124.95 , 136769.9  , 231650.92 ,\n",
       "        94141.32 , 210927.5  , 189984.17 , 192739.27 , 153421.11 ,\n",
       "       224385.4  , 176226.72 , 197775.58 , 149636.19 , 218423.53 ,\n",
       "       164178.5  , 119363.805, 127544.33 , 128973.66 , 107107.06 ,\n",
       "       239168.72 , 344069.56 , 262039.   , 262796.22 , 168344.25 ,\n",
       "       171495.5  , 255489.69 , 112308.31 , 161030.84 , 104992.57 ,\n",
       "       168507.95 , 178132.33 , 112625.44 , 117477.31 , 264687.72 ,\n",
       "       104475.33 ,  75842.08 , 222464.44 , 149250.72 , 288009.7  ,\n",
       "       206930.42 , 221334.14 , 113682.34 , 188720.4  , 161005.81 ,\n",
       "       304508.6  , 172046.34 , 193194.31 , 195331.45 , 161078.55 ,\n",
       "        73099.46 , 151167.1  , 118802.06 , 142882.11 ,  90772.31 ,\n",
       "       185409.8  , 158402.75 , 160429.03 , 225282.6  , 172791.3  ,\n",
       "       136143.66 , 147817.14 , 135133.05 ,  95846.29 , 150179.56 ,\n",
       "       140814.17 , 205264.45 , 275750.75 , 187405.78 , 117114.31 ,\n",
       "       126669.84 , 227652.89 , 143917.25 , 199364.11 , 177835.62 ,\n",
       "       179229.9  ,  96762.79 , 172999.05 , 152870.69 , 120750.6  ,\n",
       "       186126.4  , 105969.56 , 117447.12 , 132490.66 ,  81889.84 ,\n",
       "       177777.14 ,  89444.21 , 251489.5  , 144700.06 , 128019.375,\n",
       "       151489.6  ,  95534.625, 165158.22 , 335479.38 , 280111.97 ,\n",
       "       278980.53 , 252128.4  , 195135.61 , 232129.39 , 129780.   ,\n",
       "       133424.53 , 125317.34 , 167404.55 , 238341.94 ,  97726.3  ,\n",
       "       197713.53 , 174612.5  , 166124.6  , 273495.34 ,  76442.19 ,\n",
       "       122764.07 , 496930.94 , 149375.4  , 190546.81 , 186876.66 ,\n",
       "       187947.7  , 235181.   , 178726.23 ,  90227.66 , 180721.22 ,\n",
       "       128719.83 , 192886.22 , 144342.75 ,  68172.65 , 338655.8  ,\n",
       "       143942.97 , 119320.59 , 112149.33 , 168538.16 , 137479.19 ,\n",
       "       141620.23 , 154687.03 , 273172.5  , 166978.62 ,  41731.996,\n",
       "       285418.53 , 362984.97 , 234319.38 , 199280.38 , 198238.22 ,\n",
       "       141993.84 , 130853.75 , 246275.   , 197260.6  , 267975.5  ,\n",
       "       123582.95 , 165994.56 , 160962.44 , 184944.61 , 152360.69 ,\n",
       "       161824.77 , 246828.5  , 174246.5  , 251766.81 , 115167.766,\n",
       "       185583.06 , 299616.78 , 217133.9  , 169317.28 , 186206.06 ,\n",
       "       201824.47 , 177755.52 , 141684.42 , 114022.64 , 190265.61 ,\n",
       "       196828.06 , 154013.94 , 261257.48 , 107662.96 , 140781.48 ,\n",
       "       196520.06 , 166378.62 , 180493.8  , 228911.3  , 119019.86 ,\n",
       "       120512.16 , 243944.72 , 115195.25 , 108804.02 , 177234.77 ,\n",
       "       114199.22 , 177297.88 ,  93265.83 , 300329.9  ,  82629.23 ,\n",
       "       145944.94 ,  91141.19 , 206097.1  , 104725.79 , 136173.06 ,\n",
       "       138366.6  , 106276.734, 168555.47 , 197121.52 , 154801.89 ,\n",
       "        56498.51 , 155318.31 , 290455.88 , 241381.27 , 199090.23 ,\n",
       "       181296.62 , 307001.8  , 203915.03 , 259059.83 , 177092.2  ,\n",
       "       182628.17 , 133394.4  , 222298.4  , 128411.06 , 101263.39 ,\n",
       "       156987.6  , 141566.81 , 135939.11 , 390078.03 , 103546.69 ,\n",
       "       174832.67 , 177536.5  , 142314.89 , 137084.81 ,  68171.53 ,\n",
       "       213595.58 , 181918.95 , 203322.03 , 191333.67 , 182046.53 ,\n",
       "        97376.164, 144283.8  , 138459.12 ,  85469.734, 209196.62 ,\n",
       "       193354.61 , 146445.34 , 106991.11 , 154078.78 ,  81885.03 ,\n",
       "       130637.84 , 173748.25 , 145274.4  , 430581.9  , 164030.95 ,\n",
       "       180517.75 ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(train_data_)\n",
    "train_data_sc = sc.transform(train_data)\n",
    "test_data_sc = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_result = test[['OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea',\n",
    "          'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']]\n",
    "X_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
